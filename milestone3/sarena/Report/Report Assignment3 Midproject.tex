\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[french] {babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{ulem}
\usepackage{amssymb}
\usepackage{url}
\usepackage[a4paper]{geometry}
\geometry{hscale=0.7,vscale=0.7,centering}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{moreverb}
\usepackage{listings}
\newtheorem{theorem}{Théorème}[section]
\newtheorem{defi}{Définition}[section] 
\newtheorem{prop}{Propriété}[section] 
\usepackage{color}
\definecolor{gris}{rgb}{0.95,0.95,0.95}
\lstset{numbers=left, tabsize=4, backgroundcolor=\color{gris},
frame=single, breaklines=true,
keywordstyle=\color{black},
stringstyle=\ttfamily,
framexleftmargin=6mm, xleftmargin=6mm}
%opening
\title{LINGI 2261 : Artificial Intelligence \\
Assignement 3 - Mid-Project}
\author{Rochet Florentin - Debroux Léonard} 
\date{Année académique 2011-2012}

\begin{document}

	\begin{titlepage}
		\begin{center}
			{\huge LINGI2261: Artificial Intelligence}\\
			\vspace{0.4cm}
			
			{\Large {Professor : Yves Deville\\ \vspace{0.2cm} Teaching assistants : Cyrille Dejemeppe and Jean-Baptiste Mairy  }}\\
			\vspace{0.6cm}
			
			{\Large \textit{ Assignement3 : Adversarial Search}}\\
			\vspace{1.2cm}

			\texttt{}\\
			\vspace{0.2cm}

			\includegraphics[height=10cm]{pageGarde.png}\\
			\vspace{0.1cm}
			{\Large \textbf{Universit\'e Catholique de Louvain}}
			\vspace{0.7cm}

			Groupe 37 \\
			\vspace{0.2cm}
			
			Florentin Rochet \\
			Léonard Debroux\\
			\vspace{0.2cm}
			2012-2013\\
		\end{center}
	\end{titlepage}

	\newpage
	

	\section{Scipion}
	
		\subsection{Draw the game tree for a depth of 2, i.e. one turn for each player.}
		\subsection{Evaluate the value of the leaves using the heuristic function (on the figure you
draw in 1, you don’t have to implement it!).}
		\subsection{Using the MiniMax algorithm, find the value of the other nodes.}
		\subsection{Circle the move the root player should do.}
		
	\section{Alpha-Beta search}	
		\subsection{Perform the MiniMax algorithm on the tree in Figure 4, i.e. put a value to each node. Circle the move the root player should do.}
		\subsection{Perform the Alpha-Beta algorithm on the tree. At each non terminal node, put the successive values of $\alpha$ and $\beta$. Cross out the arcs reaching non visited nodes. Assume a left-to-right node expansion.}
		\subsection{Do the same, assuming a right-to-left node expansion instead}
		\subsection{Can the nodes be ordered in such a way that Alpha-Beta pruning can cut off more branches (in a left-to-right node expansion)? If no, explain why; if yes,
give the new ordering and the resulting new pruning.}
		Yes it can. here the new ordering :
	\section{Sarena}
		\subsection{A basic Alpha-Beta agent}
		
		\subsection{Comparison of MiniMax and Alpha-Beta}
			\subsubsection{Question 4: What action will be played when using the MiniMax algorithm and when using the Alpha-Beta algorithm? Is there a difference between both results?}
			The two played actions will be the same because the difference between MiniMax and Alpha-Beta is that the latter uses pruning. The only difference between the two results is that Alpha-Beta will visit less nodes than MiniMax and so, less time is needed.
			\subsubsection{Question 5: For both algorithms, give the time taken and the number of nodes that are visited when searching the tree. Does this meet your expectations?}
				The results of the tests are below. We didn't get to completion by using the MiniMax strategy, the amount of nodes goes past 10M nodes and so, we didn't let the game run long enough to see a result.
				\begin{center}
					\begin{tabular}{|c||c|c|}
						\hline 
						 & \textbf{Time [s]} & \textbf{Nodes} \\ 
						\hline 
						\textbf{MiniMax} & / & / \\ 
						\hline 
						\textbf{Alpha-Beta} & 87.82 & 371,175 \\
						\hline 
					\end{tabular}
				\end{center} 
				This meets our expectations as we first run Alpha-Beta and it already took some time, it is normal that MiniMax takes so much time.

			\subsubsection{Question 6: For both algorithms, report the number of nodes that are visited at each depth level of the tree.a What do you observe? Explain.}
				As we only reached a solution for the Alpha-Beta algorithm here is the number of nodes visited per depth.
				\begin{center}
					\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
						\hline 
						\textbf{Depth} & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ 
						\hline 
						\textbf{Nodes} & 1 & 24 & 63 & 659 & 2,113 & 11,427 & 28,131 & 78,554 & 95,481 & 109,704 & 45,018 \\ 
						\hline 
					\end{tabular} 
				\end{center}
				What is worth observing is the obvious result of 24 nodes at the depth 1 which correspond to $ 1*4 + 4*3 + 4*2 $ that is the possible moves per position (center, edge and corner).\\
				Also, we can see that at the depth 10, there is less moves than for the depth 9. That is because some game progressions can lead to only 9 moves to completion.
			
			\subsection{Evaluation function}
				\subsubsection{Question 7: Describe your evaluation function.}
				The evaluation function look for each towers of the board. For each of them, it first calculate all the possible actions and create an object Action \footnote{see our class Action}, then it checks if this action is contained in our dictionaries of "mustDo" and "suicide" move. Those dictionaries are used to recognize some patterns that we assume they must be done in the next move. It's a look-forward for some precise case. A weight is associate in each of those pattern\footnote{see the action again} and this weight is part of the score. The weight is positive for mustDo and negative for suicide.\\
After, we compute the points associate to each coins that are lost or win. the points are positive for win coins and negative for the lost coins. Those points are add to the score.
And finally, the function count the numbers of yellow coins and red coins that are, first on bottom of towers located in blank case and second on top of towers located in arrows coins. the value (yellowCoins-redCoins) is added to the score, which make the final score.\\
This score is positive if we are evaluate to winner and negative on the other hand.

				\subsubsection{Question 8: In Alpha-Beta, the evaluation function is used to evaluate leaf nodes (when the cut-off occurs). As seen in previous questions, the pruning of Alpha-Betadepends on the order of the successors. Explain how your evaluation function could be used to (we hope) obtain more pruning with Alpha-Beta. Are there any drawbacks to your approach?}
					The evaluation function can be used at each state that we compute to order successively every level of the search tree. The order is increasing of decreasing following the parent (min or max).\\
					This increases the change to have pruning when backtracking the evaluations of the leaves.\\
					The only drawback would be the computation time to perform the sort, but as it increases the pruning enough, it is better to do so.
				\subsubsection{Question 9: Make an agent using the successor function of the basic player (section 3.1), using your new evaluation function and cutting the tree at its root to use the evaluation function on its direct successors (you can achieve this by making cutoff always return True). Let this agent play against another similar agent using Board.get\_score as evaluation function. Try out multiple matches and vary who plays first. How well does your evaluation function fare?}
					Our evaluation function alone doesn't do so well when search with a depth of 1, we launched 10 games, 5 with basic\_player beginning and 5 with the other beginning. The basic\_player won 9 times over 10, the other player won only once as he began the game.
			
			\subsection{Successors function}
				\subsubsection{Question 10: Give an upper bound on the number of successors for one state.}
					There is at most 120 possible actions on one board, we can easily convince ourselves that this is the very first state that allows the most actions. Then, we count how many possible actions for each coin which gives $4*2+4*4*3+4*4*4$ (corner, edges and center coins).
				\subsubsection{Question 11: From random games (at least 100), compute the average number of possible
actions at each step of the game. Plot the results in a graph. What do you observe?}
					Here is the graph generated :
					\begin{figure}[h!]
						\centering
							\includegraphics[scale=0.4]{GraphPossActions.png}
						\caption{Number of possible actions per step}
						\label{fig:server_connection}	
					\end{figure}
					We can observe that for the 25 first steps, the decrease is linear. The reason why it stop the be linear between the 25th and the 35 steps is because all games do not reach that much steps.
					
				\subsubsection{Question 12: Are all these successors necessary to be exhaustive (think about symmetry)? Why? If not, how will you consider only the necessary states?}
					There can be symmetrical states:\\
					If we have two independent action $a$ and $b$, the traces $a\rightarrow b$ and $b\rightarrow a$ lead to the same state, so it is unnecessary to treat it twice.\\
					The way to deal with those states is to add a dictionary containing all the visited states for one step of the game. When an action leads to a state that is already in it, we simply don't yield it.
				\subsubsection{Question 13: If the number of successors is still too large, can you think of states that might be ignored, at the expense of loosing completeness?}
					Yes, there are some "suicidal" action that a normal player wouldn't do because they would lead to certain defeat. We can assume that the opponent won't play "his suicidal action" and we don't want our AI to perform its own "suicidal actions". Thus, we can simply ignore those actions.
				\subsubsection{Question 14: Describe your successors function.}
					Our successor gets all the possible actions from a state, and only keeps the asymmetrical ones. Than it performs a sort on the states, the order depending on the player that perform the actions (min or max) and then yields all the actions in that order.
				\subsubsection{Question 15: On average, how deep can you explore the tree made by your successors function starting from random initial states (as generated by the constructor of the Board class) in less than 30 seconds? Use an Alpha-Beta agent with the basic evaluation function and increase progressively the cut-off depth.}
				
			\subsection{Cut-off function}
				\subsubsection{Question 16: The cutoff method receives an argument called depth. Explain precisely what is called the depth in the minimax.py implementation. Illustrate on an example (draw a search tree and indicate the depths).}
					When drawing the tree of the search, the depth is the level on which we are. It represents in the minimax algorithm the number of action we see in advance. In other words, for a depth d, it means that we have though of all the actions scheme in a range of d actions.\\
					\begin{huge}
						AJOUTER LE DESSIN
					\end{huge}
				\subsubsection{Question 17: Explain why it might be useful (for the Sarena contest) to cut off the search for another reason than the depth.}
					There is two other reasons than depth to cut the search in our case. the first one is the time that is taken to perform the search and the second one is the detection of the suicides as we want to avoid computing their children.
				\subsubsection{Question 18: Describe your cut-off function.}
					Our cut-off function works in three phases, the first is checking if there is enough time remaining. If not, the search of depth 2 or 1.\\
					Then, we check if the current state made from a suicidal move, if yes, it returns True.\\
					And finally, if the search took to much time, we decrease the depth of the following search, if not, we increase it.
\end{document}